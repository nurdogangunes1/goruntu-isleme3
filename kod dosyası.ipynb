{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY6qNpUMGF9d",
        "outputId": "78be5a58-eb12-45f2-9adf-87fc4d0e9b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdGaeKVpGWpI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BspFaR3WGanh"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8zPKzIaGeLa"
      },
      "outputs": [],
      "source": [
        "def resize_images(input_dir, output_dir, size=(224, 224)):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for root, dirs, files in os.walk(input_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    img = Image.open(file_path)\n",
        "                    img = img.resize(size, Image.ANTIALIAS)\n",
        "\n",
        "                    # Save to the corresponding location in the output directory\n",
        "                    relative_path = os.path.relpath(root, input_dir)\n",
        "                    output_path = os.path.join(output_dir, relative_path)\n",
        "\n",
        "                    if not os.path.exists(output_path):\n",
        "                        os.makedirs(output_path)\n",
        "\n",
        "                    img.save(os.path.join(output_path, file))\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file {file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCV6LHgzGihA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgxPlSGUGlZa",
        "outputId": "aa62a0c4-0f33-4eb9-ab16-aef2c41d3873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = VGG16(weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0AvEQOYGr19"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/dataset_resized/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset_resized/test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZHgwi05GvFP",
        "outputId": "3525ba3f-f445-489b-84dc-f2424af30d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2216 images belonging to 5 classes.\n",
            "Found 632 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Modelinizin girdi boyutuna göre ayarlayın\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # İkili sınıflandırma için 'binary', çoklu sınıflandırma için 'categorical' kullanın\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRIZ1qM4G2mq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Önceden eğitilmiş VGG16 modelini yükleyin ve transfer öğrenme için kullanın\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Yeni bir model oluşturun\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Bazı katmanları dondurun (eğitim sırasında değiştirilmesin)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Modeli derleyin\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=3\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tmuE96IQzPE",
        "outputId": "e73c4a9b-7d39-4c7f-e46b-c72e3c902de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "69/69 [==============================] - 785s 11s/step - loss: -1543.8145 - accuracy: 0.1255 - val_loss: -3461.4368 - val_accuracy: 0.1053\n",
            "Epoch 2/3\n",
            "69/69 [==============================] - 40s 580ms/step - loss: -7965.3242 - accuracy: 0.1227 - val_loss: -11674.4189 - val_accuracy: 0.1069\n",
            "Epoch 3/3\n",
            "69/69 [==============================] - 40s 577ms/step - loss: -20683.0156 - accuracy: 0.1223 - val_loss: -25417.8906 - val_accuracy: 0.1053\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cacb81e5180>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/dataset_resized/model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueeA8QvEUaYt",
        "outputId": "e7b35d09-5e04-4e1b-eed6-d67f18073560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prep_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "    return img_array\n",
        "\n",
        "def predict_image(model, image_path):\n",
        "    img_array = load_and_prep_image(image_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    return prediction\n",
        "\n",
        "# Örnek görüntü dosyasının yolunu belirleyin\n",
        "image_path = '/content/drive/MyDrive/dataset_resized/test görüntüleri/2024-rolls-royce-phantom-102-64bad70ba7661.jpg'\n",
        "prediction = predict_image(model, image_path)\n",
        "print(f'Prediction: {prediction}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_h08M3TUxmT",
        "outputId": "ccb57455-5712-4321-d966-13caeb7971d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Prediction: [[1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Audi', 'Hyundai Creta', 'Swift', 'Rolls Royce', 'Toyota Innova']\n"
      ],
      "metadata": {
        "id": "_kfCzhbNW0gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/dataset_resized/model.h5')"
      ],
      "metadata": {
        "id": "l4pqjq5GW8Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/87c5d29d2bd3b2dda371427fe9427b60.jpg'  # Test etmek istediğiniz resmin yolu\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Aynı ölçeklendirme işlemini uygulayın"
      ],
      "metadata": {
        "id": "JpUHaI0TXIHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(img_array)\n",
        "\n",
        "def decode_prediction(prediction, class_names):\n",
        "    predicted_class = class_names[np.argmax(prediction[0])]\n",
        "    return predicted_class\n",
        "\n",
        "predicted_class = decode_prediction(prediction, class_names)\n",
        "print(f'Predicted Class: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrBeK0zWXUO9",
        "outputId": "0011dbaa-f549-49d7-fd1c-ea5131107cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted Class: Audi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXCSe2IZY0SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(img_array)\n",
        "\n",
        "def decode_prediction(prediction, class_names):\n",
        "    predicted_class = class_names[np.argmax(prediction[0])]\n",
        "    return predicted_class\n",
        "\n",
        "predicted_class = decode_prediction(prediction, class_names)\n",
        "print(f'Predicted Class: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzCeaB3zX9WY",
        "outputId": "b71cd287-4467-4b0d-ec55-7f06e2960272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted Class: Audi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def count_files(directory):\n",
        "    counter = Counter()\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(('png', 'jpg', 'jpeg')):\n",
        "                counter[os.path.basename(root)] += 1\n",
        "    return counter\n",
        "\n",
        "train_counter = count_files(train_dir)\n",
        "test_counter = count_files(test_dir)\n",
        "\n",
        "print(f'Train data distribution: {train_counter}')\n",
        "print(f'Test data distribution: {test_counter}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrmoD8P9YEsL",
        "outputId": "ba31fb91-082a-47a1-cb54-45f9841fb084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data distribution: Counter({'Toyota Innova': 670, 'Audi': 540, 'Swift': 424, 'Rolls Royce': 311, 'Hyundai Creta': 271})\n",
            "Test data distribution: Counter({'Audi': 199, 'Toyota Innova': 190, 'Swift': 102, 'Rolls Royce': 74, 'Hyundai Creta': 67})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Modeli yükleyin\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/dataset_resized/model.h5')\n",
        "\n",
        "# Sınıf isimlerini belirleyin\n",
        "class_names = ['Hyundai Creta','Audi',  'Swift', 'Rolls Royce', 'Toyota Innova']\n",
        "\n",
        "# Test etmek istediğiniz resmi yükleyin ve ön işleyin\n",
        "img_path = '/content/drive/MyDrive/dataset_resized/test/Rolls Royce/159.jpg'  # Test etmek istediğiniz resmin yolu\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Aynı ölçeklendirme işlemini uygulayın\n",
        "\n",
        "# Tahmini alın\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Tahmini decode edin\n",
        "def decode_prediction(prediction, class_names):\n",
        "    predicted_class = class_names[np.argmax(prediction[0])]\n",
        "    return predicted_class\n",
        "\n",
        "predicted_class = decode_prediction(prediction, class_names)\n",
        "print(f'Predicted Class: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfTlrdfJY1qL",
        "outputId": "45955f10-9d75-4eb5-fa97-4bf2bbc3077a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 209ms/step\n",
            "Predicted Class: Hyundai Creta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerekli kütüphaneleri yükleyin\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Google Drive'ı bağlayın\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Veri yollarını belirleyin\n",
        "train_dir = '/content/drive/MyDrive/dataset_resized/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset_resized/test'\n",
        "\n",
        "# Veri artırma ve yükleme\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Multiple classes\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Multiple classes\n",
        ")\n",
        "\n",
        "# Modeli oluşturma\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # Output layer for multiple classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Bazı katmanları dondurun\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Modeli derleyin\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Sınıf ağırlıklarını hesapla\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Modeli eğitin\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "# Modeli kaydetme\n",
        "model.save('/content/drive/MyDrive/dataset_resized/model.h5')\n",
        "\n",
        "# Sınıf isimlerini belirleyin\n",
        "class_names = ['Audi', 'Hyundai Creta', 'Swift', 'Rolls Royce', 'Toyota Innova']\n",
        "\n",
        "# Modeli yükleyin\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/dataset_resized/model.h5')\n",
        "\n",
        "# Test etmek istediğiniz resmi yükleyin ve ön işleyin\n",
        "img_path = '/content/drive/MyDrive/dataset_resized/test/Rolls Royce/176.jpg'  # Test etmek istediğiniz resmin yolu\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Aynı ölçeklendirme işlemini uygulayın\n",
        "\n",
        "# Tahmini alın\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Tahmini decode edin\n",
        "def decode_prediction(prediction, class_names):\n",
        "    predicted_class = class_names[np.argmax(prediction[0])]\n",
        "    return predicted_class\n",
        "\n",
        "predicted_class = decode_prediction(prediction, class_names)\n",
        "print(f'Predicted Class: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNOQuospZZL5",
        "outputId": "7b6ce8cf-905c-4625-c779-5cc879f9f354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 2216 images belonging to 5 classes.\n",
            "Found 632 images belonging to 5 classes.\n",
            "Epoch 1/10\n",
            "69/69 [==============================] - 42s 584ms/step - loss: 1.7058 - accuracy: 0.5119 - val_loss: 0.8097 - val_accuracy: 0.7204\n",
            "Epoch 2/10\n",
            "69/69 [==============================] - 40s 574ms/step - loss: 0.5962 - accuracy: 0.8255 - val_loss: 0.5505 - val_accuracy: 0.8125\n",
            "Epoch 3/10\n",
            "69/69 [==============================] - 40s 586ms/step - loss: 0.4064 - accuracy: 0.8796 - val_loss: 0.3466 - val_accuracy: 0.9046\n",
            "Epoch 4/10\n",
            "69/69 [==============================] - 39s 570ms/step - loss: 0.2645 - accuracy: 0.9318 - val_loss: 0.3086 - val_accuracy: 0.9013\n",
            "Epoch 5/10\n",
            "69/69 [==============================] - 38s 548ms/step - loss: 0.2089 - accuracy: 0.9515 - val_loss: 0.3587 - val_accuracy: 0.8882\n",
            "Epoch 6/10\n",
            "69/69 [==============================] - 40s 568ms/step - loss: 0.1569 - accuracy: 0.9597 - val_loss: 0.2375 - val_accuracy: 0.9260\n",
            "Epoch 7/10\n",
            "69/69 [==============================] - 39s 572ms/step - loss: 0.1341 - accuracy: 0.9693 - val_loss: 0.3496 - val_accuracy: 0.8799\n",
            "Epoch 8/10\n",
            "69/69 [==============================] - 40s 581ms/step - loss: 0.1064 - accuracy: 0.9748 - val_loss: 0.2424 - val_accuracy: 0.9161\n",
            "Epoch 9/10\n",
            "69/69 [==============================] - 40s 586ms/step - loss: 0.0810 - accuracy: 0.9831 - val_loss: 0.2717 - val_accuracy: 0.9112\n",
            "Epoch 10/10\n",
            "69/69 [==============================] - 41s 591ms/step - loss: 0.0895 - accuracy: 0.9780 - val_loss: 0.2432 - val_accuracy: 0.9194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7caaf25e79a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step\n",
            "Predicted Class: Swift\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test etmek istediğiniz resmi yükleyin ve ön işleyin\n",
        "img_path = '/content/drive/MyDrive/dataset_resized/test görüntüleri/800px-2019_Rolls-Royce_Cullinan_V12_Automatic_6.75_Front.jpg'  # Test etmek istediğiniz resmin yolu\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Aynı ölçeklendirme işlemini uygulayın\n",
        "\n",
        "# Tahmini alın\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Tahmini decode edin\n",
        "def decode_prediction(prediction, class_names):\n",
        "    predicted_class = class_names[np.argmax(prediction[0])]\n",
        "    return predicted_class\n",
        "\n",
        "predicted_class = decode_prediction(prediction, class_names)\n",
        "print(f'Predicted Class: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJBvEBqgdLUh",
        "outputId": "9ac3c2be-2f61-4a24-c92f-1b1352920070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Predicted Class: Swift\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import MobileNet, preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# MobileNet modelini yükleyin\n",
        "model = MobileNet(weights='imagenet')\n",
        "\n",
        "# Test etmek istediğiniz resmin yolu\n",
        "img_path = '/content/drive/MyDrive/dataset_resized/test görüntüleri/800px-2019_Rolls-Royce_Cullinan_V12_Automatic_6.75_Front.jpg'\n",
        "\n",
        "# Resmi yükleyin ve ön işleyin\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "# Tahmini alın\n",
        "preds = model.predict(x)\n",
        "\n",
        "# Tahmini yazdırın\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "d5mlDwQtdlXg",
        "outputId": "502eff46-47d0-4b72-e9d4-d4ea502f9522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'preprocess_input' from 'tensorflow.keras.applications' (/usr/local/lib/python3.10/dist-packages/keras/api/_v2/keras/applications/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d53d4a34c5e2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'preprocess_input' from 'tensorflow.keras.applications' (/usr/local/lib/python3.10/dist-packages/keras/api/_v2/keras/applications/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRBo8fXAg6Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# MobileNet modelini yükleyin\n",
        "model = MobileNet(weights='imagenet')\n",
        "\n",
        "# Test etmek istediğiniz resmin yolu\n",
        "img_path = '/content/drive/MyDrive/görüntü işleme/test/Rolls Royce/115.jpg'\n",
        "\n",
        "# Resmi yükleyin ve ön işleyin\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "# Tahmini alın\n",
        "preds = model.predict(x)\n",
        "\n",
        "# Tahmini yazdırın\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR8B6tOedLfm",
        "outputId": "a20cb883-74b7-4499-884a-3ff12aedb2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cabf0d01b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "Predicted: [('n02814533', 'beach_wagon', 0.2681671), ('n02974003', 'car_wheel', 0.2628276), ('n04285008', 'sports_car', 0.22201599)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}